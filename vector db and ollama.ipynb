{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affc6627-adb5-4081-9847-92022aa5f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='ad9b6c1f-d9d5-46a5-83d7-4dd3ca89037d', embedding=None, metadata={'file_path': '/home/raghav/Desktop/myProjects/llamaIndexLearn/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 123, 'creation_date': '2024-03-13', 'last_modified_date': '2024-03-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, text='my name is raghav aggarwal. I am currently working as a software engineer at plutos ONE for 8 months.\\nMy current age is 24.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "documents = SimpleDirectoryReader(\"./data\").load_data()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6be2397-29d1-4179-94f8-af748e159a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is raghav aggarwal. I am currently working as a software engineer at plutos ONE for 8 months.My current age is 24.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up our Documents' content\n",
    "import re\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "    \n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "\n",
    "    # Remove specific unwanted patterns and characters\n",
    "    unwanted_patterns = [\n",
    "        \"\\\\n\", \"  —\", \"——————————\", \"—————————\", \"—————\",\n",
    "        r'\\\\u[\\dA-Fa-f]{4}', r'\\uf075', r'\\uf0b7'\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "\n",
    "    # Fix improperly spaced hyphenated words and normalize whitespace\n",
    "    content = re.sub(r'(\\w)\\s*-\\s*(\\w)', r'\\1-\\2', content)\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "\n",
    "    return content\n",
    "\n",
    "# Call function\n",
    "cleaned_docs = []\n",
    "for d in documents: \n",
    "    cleaned_text = clean_up_text(d.text)\n",
    "    d.text = cleaned_text\n",
    "    cleaned_docs.append(d)\n",
    "\n",
    "cleaned_docs[0].get_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69d8ca95-723a-45ed-b066-26700767e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94578b32-3511-4d66-b518-62b30330f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IngestionPipeline(name='default', project_name='default', transformations=[SemanticSplitterNodeParser(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7308512451b0>, id_func=None, sentence_splitter=<function split_by_sentence_tokenizer.<locals>.split at 0x730806c8b6d0>, embed_model=HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x730897f9f790>, tokenizer_name='BAAI/bge-small-en-v1.5', max_length=512, pooling=<Pooling.CLS: 'cls'>, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None), buffer_size=1, breakpoint_percentile_threshold=95), HuggingFaceEmbedding(model_name='BAAI/bge-small-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x730897f9f790>, tokenizer_name='BAAI/bge-small-en-v1.5', max_length=512, pooling=<Pooling.CLS: 'cls'>, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None)], documents=None, readers=None, vector_store=None, cache=IngestionCache(collection='llama_cache', cache=<llama_index.core.storage.kvstore.simple_kvstore.SimpleKVStore object at 0x730806cfb580>, nodes_key='nodes'), docstore=None, docstore_strategy=<DocstoreStrategy.UPSERTS: 'upserts'>, disable_cache=False, base_url='https://api.cloud.llamaindex.ai', app_url='https://cloud.llamaindex.ai', api_key=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac7a63f6-3b71-4cfb-b185-6161bdd03918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956c9033a427477f8ebc50adbeddecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='5456633a-2c77-40b8-9d18-9f96256da480', embedding=[-0.025464145466685295, 0.0018217418109998107, 0.036301493644714355, -0.06269598007202148, 0.010044224560260773, -0.006024685222655535, 0.009813617914915085, 0.0006930421805009246, -0.07265465706586838, 0.0032065147534012794, 0.048768550157547, 0.029994672164320946, 0.017686786130070686, -0.021314945071935654, -0.003585520666092634, 0.04387583211064339, -0.022485220804810524, 0.016283251345157623, 0.017121275886893272, -0.0240331944078207, 0.016842683777213097, -0.0010273057268932462, 0.012574760243296623, -0.03244088590145111, 0.051658932119607925, 0.04961613565683365, -0.02686377428472042, -0.011957031674683094, -0.03861071914434433, -0.16773803532123566, 0.05941726267337799, -0.029858024790883064, 0.05940138176083565, -0.02729140967130661, 0.010741611011326313, 0.052954524755477905, 0.03151274845004082, 0.008545652963221073, -0.02472122572362423, 0.010764176957309246, -0.02052386850118637, -0.013060014694929123, -0.02155626192688942, -0.033156659454107285, 0.016238851472735405, 0.019445547834038734, -0.04607383906841278, -0.03184262663125992, 0.025723513215780258, 0.015419362112879753, -0.059404876083135605, -0.028660058975219727, 0.005224871914833784, 0.0658363401889801, -0.07805206626653671, -0.03267049789428711, 0.041909847408533096, 0.03941218927502632, -0.04121438041329384, 0.02465500682592392, 0.018823379650712013, -0.05254624783992767, -0.22387723624706268, 0.09541839361190796, 0.02434811368584633, -0.01722475327551365, -0.012990274466574192, -0.059294719249010086, -0.051114607602357864, -0.006044426001608372, 0.004251750186085701, 0.017610831186175346, -0.043400730937719345, 0.04632945731282234, 0.04150903597474098, 0.009571024216711521, 0.023757480084896088, -0.029917096719145775, 0.07786735147237778, 0.015983078628778458, 0.0026677600108087063, -0.04201331362128258, -0.04818788915872574, -0.03172485530376434, -0.024130385369062424, 7.744959293631837e-05, 0.03692002221941948, 0.0021878026891499758, -0.0048060789704322815, 0.012465756386518478, 0.030620498582720757, -0.016354914754629135, 0.03391099348664284, 0.004207151476293802, -0.016362957656383514, -0.029049374163150787, 0.011736114509403706, 0.0015145714860409498, -0.028222685679793358, 0.4683797359466553, -0.04831495136022568, -0.01730906032025814, 0.023525770753622055, 0.05243875831365585, 0.020068729296326637, -0.007374119944870472, 0.03196863457560539, -0.022603224962949753, 0.019827120006084442, -0.027584288269281387, -0.011095731519162655, 0.044279444962739944, 0.007987478747963905, -0.03442484140396118, 0.05688883736729622, 0.04152582585811615, -0.009320499375462532, 0.026783309876918793, -0.003650345141068101, -0.029197517782449722, -0.05064322054386139, 0.04843374714255333, -0.008581635542213917, 0.005434241145849228, -0.04017823934555054, 0.001032292260788381, 0.014000349678099155, 0.08320802450180054, -0.0035924080293625593, 0.030311759561300278, 0.07580243051052094, -0.01138236466795206, -0.10593453049659729, -0.021581407636404037, 0.04559357464313507, 0.049393586814403534, 0.009338405914604664, 0.0424681156873703, 0.011502961628139019, -0.01172951515763998, -0.02853205054998398, -0.04600019007921219, 0.07042880356311798, 0.014910250902175903, -0.006913077086210251, 0.038310784846544266, 0.035564571619033813, 0.009128912352025509, 0.019489223137497902, -0.010061717592179775, 0.0017233112594112754, 0.017581915482878685, -0.0008610569057054818, -0.019925082102417946, 0.06692024320363998, 0.01793733239173889, 0.04530159384012222, -0.01675465703010559, -0.05672933906316757, 0.004456174094229937, -0.0037958864122629166, 0.02718385122716427, -0.0065451753325760365, 0.08482775837182999, 0.06372755020856857, -0.08330119401216507, -0.006935848854482174, 0.06952977925539017, 0.031221862882375717, 0.01856767013669014, 0.05248225852847099, 0.01157627534121275, 0.024532156065106392, -0.0024906385224312544, 0.07466711103916168, -0.0035645533353090286, -0.02091154269874096, 0.02569335140287876, 0.0267826896160841, 0.05127440392971039, 0.005190463270992041, -0.018997740000486374, -0.012743944302201271, 0.0425373874604702, -0.027024172246456146, -0.023567361757159233, 0.025827556848526, 0.028550030663609505, 0.013191396370530128, -0.06774325668811798, 0.0006325604626908898, 0.033361323177814484, -0.066611148416996, 0.021765220910310745, 0.03520819917321205, -0.02242880128324032, 0.01807319186627865, -0.02451656199991703, 0.03216953203082085, -0.07163077592849731, 0.031210459768772125, -0.023082906380295753, -0.04113348200917244, 0.03295107185840607, -0.006257364526391029, 0.006481509190052748, 0.009110799990594387, 0.027246300131082535, 0.0953918918967247, 0.0003602776560001075, 0.0446767583489418, -0.04088765010237694, 0.004243335220962763, 0.007003053557127714, -0.02229321002960205, 0.04598315805196762, -0.027306267991662025, -0.020056169480085373, 0.0163187924772501, 0.008450019173324108, 0.0005543267470784485, 0.05176408216357231, -0.016961615532636642, -0.31206008791923523, -0.01262646820396185, -0.04843449965119362, -0.012596537359058857, 0.04438688978552818, 0.02218051068484783, -0.01366187073290348, -0.04899178072810173, 0.053078342229127884, -0.017001038417220116, 0.07836765795946121, 0.020932529121637344, -0.02510392852127552, -0.045134540647268295, 0.010292423889040947, 0.012119408696889877, -0.0004072667798027396, -0.004444212187081575, -0.005267895292490721, -0.019910819828510284, 0.015283789485692978, -0.012617282569408417, -0.0238286554813385, -0.054848477244377136, 0.016685275360941887, -0.029579009860754013, 0.13502228260040283, 0.027328357100486755, -0.030599193647503853, -0.04558543115854263, -0.0023524719290435314, -0.013311785645782948, 0.0448995903134346, -0.13244634866714478, 0.029429227113723755, 0.002825898816809058, 0.00353812868706882, -0.035814739763736725, -0.02137773111462593, -0.027993138879537582, -0.03340565785765648, 0.039539188146591187, 0.001598646049387753, -0.06706941872835159, -0.08206818997859955, -0.05365748703479767, -0.041881777346134186, -0.041700657457113266, 0.03231233358383179, 0.00735704367980361, 0.02059590443968773, -0.03703863546252251, -0.005990819074213505, 0.023066982626914978, -0.03058655932545662, -0.06944681704044342, -0.05454999953508377, 0.05314524471759796, 0.006398177705705166, -0.0004231350321788341, -0.05960701406002045, -0.06996144354343414, -0.035559896379709244, -0.039438072592020035, -0.008532559499144554, -0.027727704495191574, -0.013046014122664928, -0.03441346064209938, -0.016678687185049057, -0.027458764612674713, -0.009454597719013691, 0.008062103763222694, -0.1403876543045044, -0.06393729895353317, -0.02653062902390957, 0.0050329649820923805, 0.02240809053182602, 0.04447631165385246, 0.04450935497879982, -0.03032943233847618, -0.04306637868285179, -0.08473041653633118, -0.011598249897360802, 0.024790488183498383, 0.03357277810573578, 0.012967481277883053, 0.04193391278386116, 0.060086026787757874, 0.010435348376631737, 0.04292354732751846, -0.05464813858270645, -0.008524416014552116, -0.025017332285642624, 0.045071594417095184, 0.029337599873542786, 0.028753330931067467, -0.23030368983745575, 0.04500969499349594, -0.06448084115982056, -0.040374089032411575, 0.045429911464452744, -0.008501272648572922, 0.0326346755027771, 0.010016461834311485, -0.025979354977607727, 0.03257741406559944, 0.05248255655169487, 0.039256803691387177, 0.03231906145811081, 0.02575298398733139, 0.05330897495150566, 0.021757451817393303, 0.012466687709093094, 0.018182212486863136, 0.008472708985209465, -0.009655177593231201, 0.04830820858478546, 0.026142211630940437, 0.0947558581829071, -0.04510525241494179, 0.03283640742301941, -0.02459883876144886, -0.06138099357485771, -0.008383871987462044, 0.036570169031620026, 0.030136479064822197, -0.03379961848258972, -0.024422885850071907, 0.0809001624584198, -0.0017064204439520836, -4.127856300328858e-05, 0.017639877274632454, -0.038097482174634933, 0.013362132012844086, -0.03588705509901047, 0.0324271135032177, 0.022130051627755165, -0.012648971751332283, -0.02674567699432373, 0.0402008593082428, 0.09286601096391678, 0.012369293719530106, 0.00025969845592044294, -0.024741513654589653, -0.006921341177076101, -0.06437124311923981, 0.0014670316595584154, -0.004373455420136452, 0.028443772345781326, 0.024935126304626465, -0.005271493457257748, 0.016982391476631165, -0.006466911640018225, -0.04473339766263962, -0.046980585902929306, -0.05800029635429382, -0.02072841115295887, 0.021606607362627983, 0.07182716578245163, 0.041552722454071045, 0.02048087678849697], metadata={'file_path': '/home/raghav/Desktop/myProjects/llamaIndexLearn/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 123, 'creation_date': '2024-03-13', 'last_modified_date': '2024-03-13'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ad9b6c1f-d9d5-46a5-83d7-4dd3ca89037d', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/home/raghav/Desktop/myProjects/llamaIndexLearn/data/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 123, 'creation_date': '2024-03-13', 'last_modified_date': '2024-03-13'}, hash='2392a84b92e5ae7b8c9c2cac7461e1a5091a9ade4c5afceff23d42570c62a390')}, text='my name is raghav aggarwal. I am currently working as a software engineer at plutos ONE for 8 months.My current age is 24.', start_char_idx=0, end_char_idx=122, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cODE TO STORE TO PINECONE DATABASE\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\") or \"a5f741a7-353b-4c19-9864-22ea5fc39a3e\"\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "pinecone_index = pc.Index(\"huggingface\")\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SemanticSplitterNodeParser(\n",
    "            buffer_size=1,\n",
    "            breakpoint_percentile_threshold=95, \n",
    "            embed_model=embed_model,\n",
    "            ),\n",
    "        embed_model,\n",
    "        ],\n",
    "        vector_store=vector_store  # Our new addition\n",
    "    )\n",
    "\n",
    "# Now we run our pipeline!\n",
    "pipeline.run(documents=cleaned_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785d93b9-b08e-4961-bd74-23fdc8c79584",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c8d00c-03e3-4851-9588-6df9cde9e7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=False, api_key=None, index_name=None, environment=None, namespace=None, insert_kwargs={}, add_sparse_vector=False, text_key='text', batch_size=100, remove_text_from_metadata=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b01b147-4f01-4ff0-88f6-e1c233e15c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not ere\n",
      "here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever at 0x750a42c63940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.llms.ollama import Ollama\n",
    "print(\"not ere\")\n",
    "Settings.llm = Ollama(model=\"phi:2.7b\",request_timeout=300)\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "# Instantiate VectorStoreIndex object from your vector_store object\n",
    "vector_index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "\n",
    "print(\"here\")\n",
    "# Grab 1 search results\n",
    "retriever = VectorIndexRetriever(index=vector_index, similarity_top_k=1)\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21cebae2-1893-4ad9-be11-0faf5856a8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my name is raghav aggarwal. I am currently working as a software engineer at plutos ONE for 8 months.My current age is 24.']\n"
     ]
    }
   ],
   "source": [
    "# Query vector DB\n",
    "answer = retriever.retrieve('where is raghav working at')\n",
    "\n",
    "# Inspect results\n",
    "print([i.get_content() for i in answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52e615e-2628-424c-af45-2b2625e38622",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x750a41e2d3f0> HERE\n",
      " Based on the given context information, it can be inferred that Raghav is currently working as a software engineer at Plutos ONE for 8 months. However, this cannot be confirmed without further information about his previous work history or job titles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# Pass in your retriever from above, which is configured to return the top 5 results\n",
    "# query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "query_engine = vector_index.as_query_engine()\n",
    "print(query_engine,\"HERE\")\n",
    "# query_engine = vector_index.as_query_engine()\n",
    "# Now you query:\n",
    "llm_query = query_engine.query('where is raghav working at')\n",
    "print(llm_query) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638b0c5d-b7b2-40e0-afba-9746012a69d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine object at 0x73a7dd191cf0> HERE\n",
      "I cannot directly reference the given context in my answer, but based on the information provided, it seems that you are describing a situation where you were a founder of an online store builder software company, and you are discussing the initial seed funding you received to launch your venture.\n",
      "\n",
      "Given this context, it is likely that you are using some form of business model or strategy to guide your company's development and growth. Without more information, I cannot pinpoint a specific model or framework you are using, but some possibilities include:\n",
      "\n",
      "1. Lean Startup Model: This model emphasizes rapid experimentation, customer feedback, and continuous improvement to build and launch a minimum viable product (MVP) quickly.\n",
      "2. Business Model Canvas: This framework provides a visual representation of a company's business model, including its key components such as value proposition, revenue streams, and cost structure.\n",
      "3. Customer Development Model: This model focuses on understanding customer needs and validating assumptions about the market and product through customer interviews and feedback.\n",
      "4. Design Thinking Model: This model emphasizes a human-centered approach to problem-solving, involving empathy for users, ideation of solutions, prototyping, and testing.\n",
      "\n",
      "Without more context or information, it is difficult to provide a more specific answer to your query.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# Pass in your retriever from above, which is configured to return the top 5 results\n",
    "# query_engine = RetrieverQueryEngine(retriever=retriever)\n",
    "query_engine = vector_index.as_query_engine()\n",
    "print(query_engine,\"HERE\")\n",
    "# query_engine = vector_index.as_query_engine()\n",
    "# Now you query:\n",
    "llm_query = query_engine.query('what model I am using')\n",
    "print(llm_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "716be3d8-0161-437a-b914-2adcc72dcf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QueryEngineComponent' object has no attribute 'as_query_component'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_engine \u001b[38;5;241m=\u001b[39m \u001b[43mquery_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_query_component\u001b[49m(streaming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m query_engine\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'QueryEngineComponent' object has no attribute 'as_query_component'"
     ]
    }
   ],
   "source": [
    "query_engine = query_engine.as_query_component(streaming=True)\n",
    "query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b2745-3a59-4df8-9f43-878d28dded5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
